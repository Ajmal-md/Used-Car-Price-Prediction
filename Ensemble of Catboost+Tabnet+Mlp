import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_squared_error, mean_absolute_error,
r2_score

# MLP (Neural Network)
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout
# CatBoost
from catboost import CatBoostRegressor
# TabNet
from pytorch_tabnet.tab_model import TabNetRegressor
import torch
# Load dataset
file_path = "/content/encoded_dataset.csv" # Update your dataset path
df = pd.read_csv(file_path)
# Define target and features
target_column = "sale_price"
X = df.drop(columns=[target_column]) # Features
y = df[target_column] # Target
# Split dataset
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,
random_state=42)
# Convert all columns in X_train and X_test to numeric type
X_train = X_train.apply(pd.to_numeric, errors='coerce')
X_test = X_test.apply(pd.to_numeric, errors='coerce')
# Fill NaN values if any (replace with your preferred strategy)
X_train.fillna(X_train.mean(), inplace=True)
X_test.fillna(X_test.mean(), inplace=True)
# Normalize features for MLP & TabNet
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)
# ------------------------- MLP Model -------------------------

mlp_model = Sequential([
Dense(128, activation="relu", input_dim=X_train_scaled.shape[1]),
Dropout(0.3),
Dense(64, activation="relu"),
Dropout(0.3),
Dense(1, activation="linear")
])
mlp_model.compile(optimizer="adam", loss="mse", metrics=["mae"])
mlp_model.fit(X_train_scaled, y_train, epochs=50, batch_size=32,
verbose=1)
# Predict with MLP
mlp_preds = mlp_model.predict(X_test_scaled).flatten()
# ------------------------- CatBoost Model -------------------------
catboost_model = CatBoostRegressor(verbose=0, random_seed=42)
catboost_model.fit(X_train, y_train)
catboost_preds = catboost_model.predict(X_test)
# ------------------------- TabNet Model -------------------------
tabnet_model = TabNetRegressor()
# Convert to NumPy arrays and ensure float32 data type
tabnet_model.fit(
X_train.values.astype(np.float32),
y_train.values.reshape(-1, 1).astype(np.float32),
max_epochs=50,
patience=10,
batch_size=256
)
# Predict with TabNet
tabnet_preds =
tabnet_model.predict(X_test.values.astype(np.float32)).flatten()
# ------------------------- Ensemble (Averaging) -------------------------
ensemble_preds = (mlp_preds + catboost_preds + tabnet_preds) / 3
# ------------------------- Evaluate Model -------------------------
mse = mean_squared_error(y_test, ensemble_preds)
rmse = np.sqrt(mse)

mae = mean_absolute_error(y_test, ensemble_preds)
r2 = r2_score(y_test, ensemble_preds)
print(f"Ensemble Model Performance:")
print(f"MSE: {mse:.4f}")
print(f"RMSE: {rmse:.4f}")
print(f"MAE: {mae:.4f}")
print(f"R2 Score: {r2:.4f}")
# Sample predictions
print("Sample Predictions:")
print("Actual:", y_test.values[:5])
print("Predicted:", ensemble_preds[:5])
